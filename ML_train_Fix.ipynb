{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2962fbf6-2635-4d02-bd53-906092e9a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7aab70a-4c79-48f0-97f0-4bbf32271389",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')  # 全ての図を明示的に閉じる\n",
    "matplotlib.use('Agg')  # その後バックエンドを切り替え\n",
    "\n",
    "# グラフ出力用のディレクトリを作成\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# バックエンド設定\n",
    "matplotlib.use('Agg')  # 非インタラクティブなバックエンドを使用\n",
    "\n",
    "class AnalyzeIris:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "        self.model_scores = {}\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"irisデータセットを取得し、必要な形式に変換する\"\"\"\n",
    "        iris = load_iris()\n",
    "        self.feature_names = iris.feature_names\n",
    "        self.target_names = iris.target_names\n",
    "        \n",
    "        # データフレームに変換\n",
    "        self.data = pd.DataFrame(data=iris.data, columns=self.feature_names)\n",
    "        self.data['target'] = iris.target\n",
    "        self.data['species'] = self.data['target'].map({\n",
    "            0: self.target_names[0],\n",
    "            1: self.target_names[1],\n",
    "            2: self.target_names[2]\n",
    "        })\n",
    "        \n",
    "        # X, yに分割\n",
    "        self.X = self.data[self.feature_names]\n",
    "        self.y = self.data['target']\n",
    "        \n",
    "        return self.data\n",
    "\n",
    "    def get_correlation(self):\n",
    "        \"\"\"変数間の相関係数を計算して表示する\"\"\"\n",
    "        corr = self.X.corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.savefig(f'{output_dir}/correlation_matrix.png')\n",
    "        plt.close()\n",
    "        return corr\n",
    "\n",
    "    def pair_plot(self, diag_kind=None):\n",
    "        # データフレームの作成\n",
    "        df = pd.DataFrame(data=self.X)\n",
    "        df.columns = self.feature_names\n",
    "        df['species'] = [self.target_names[i] for i in self.y]\n",
    "    \n",
    "        if diag_kind == 'hist' or diag_kind == 'kde':\n",
    "            # 指定された対角成分のみ表示\n",
    "            g = sns.pairplot(df, hue='species', diag_kind=diag_kind)\n",
    "            g.fig.suptitle(f'Pair Plot with {diag_kind.upper()} on Diagonal', y=1.02)\n",
    "            plt.savefig(f'{output_dir}/pairplot_{diag_kind}.png')\n",
    "            plt.close()\n",
    "        else:\n",
    "            # ヒストグラムバージョン\n",
    "            g1 = sns.pairplot(df, hue='species', diag_kind='hist')\n",
    "            g1.fig.suptitle('Pair Plot with Histograms on Diagonal', y=1.02)\n",
    "            plt.savefig(f'{output_dir}/pairplot_hist.png')\n",
    "            plt.close()\n",
    "        \n",
    "            # KDEバージョン\n",
    "            g2 = sns.pairplot(df, hue='species', diag_kind='kde')\n",
    "            g2.fig.suptitle('Pair Plot with KDE on Diagonal', y=1.02)\n",
    "            plt.savefig(f'{output_dir}/pairplot_kde.png')\n",
    "            plt.close()\n",
    "    \n",
    "        return\n",
    "\n",
    "    def all_supervised(self, n_neighbors=4):\n",
    "        \"\"\"複数の教師あり学習モデルを実行して評価する\"\"\"\n",
    "        # 評価対象のモデル\n",
    "        models = {\n",
    "            'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "            'LinearSVC': LinearSVC(max_iter=1000, dual='auto'), \n",
    "            'SVC': SVC(),\n",
    "            'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "            'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=n_neighbors),\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForestClassifier': RandomForestClassifier(),\n",
    "            'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "            'MLPClassifier': MLPClassifier(max_iter=1000)\n",
    "        }\n",
    "        \n",
    "        # K分割交差検証\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 結果格納用\n",
    "        self.model_scores = {}\n",
    "        \n",
    "        # 各モデルに対して評価\n",
    "        for name, model in models.items():\n",
    "            print(f\"=== {name} ===\")\n",
    "            test_scores = []\n",
    "            train_scores = []\n",
    "            \n",
    "            for train_idx, test_idx in kf.split(self.X):\n",
    "                X_train, X_test = self.X.iloc[train_idx], self.X.iloc[test_idx]\n",
    "                y_train, y_test = self.y.iloc[train_idx], self.y.iloc[test_idx]\n",
    "                \n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # トレーニングスコア計算\n",
    "                if name == 'LinearRegression':\n",
    "                    train_score = model.score(X_train, y_train)\n",
    "                    test_score = model.score(X_test, y_test)\n",
    "                else:\n",
    "                    train_score = accuracy_score(y_train, model.predict(X_train))\n",
    "                    test_score = accuracy_score(y_test, model.predict(X_test))\n",
    "                \n",
    "                train_scores.append(train_score)\n",
    "                test_scores.append(test_score)\n",
    "                \n",
    "                print(f\"test score: {test_score:.3f}, train score: {train_score:.3f}\")\n",
    "            \n",
    "            # スコアを保存\n",
    "            self.model_scores[name] = {\n",
    "                'test_scores': test_scores,\n",
    "                'train_scores': train_scores,\n",
    "                'mean_test_score': np.mean(test_scores),\n",
    "                'mean_train_score': np.mean(train_scores)\n",
    "            }\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        return self.model_scores\n",
    "\n",
    "    def get_supervised(self):\n",
    "        \"\"\"学習結果をDataFrameで返す\"\"\"\n",
    "        if not self.model_scores:\n",
    "            return None\n",
    "        \n",
    "        results = []\n",
    "        for model_name, scores in self.model_scores.items():\n",
    "            for i, (test, train) in enumerate(zip(scores['test_scores'], scores['train_scores'])):\n",
    "                results.append({\n",
    "                    'model': model_name,\n",
    "                    'fold': i+1,\n",
    "                    'test_score': test,\n",
    "                    'train_score': train\n",
    "                })\n",
    "        \n",
    "        df_scores = pd.DataFrame(results)\n",
    "        return df_scores\n",
    "\n",
    "    def best_supervised(self):\n",
    "        \"\"\"最良のモデルを返す\"\"\"\n",
    "        if not self.model_scores:\n",
    "            return None, 0\n",
    "        \n",
    "        best_model = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for model_name, scores in self.model_scores.items():\n",
    "            mean_score = scores['mean_test_score']\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_model = model_name\n",
    "        \n",
    "        return best_model, best_score\n",
    "\n",
    "    def plot_feature_importances_all(self):\n",
    "        \"\"\"特徴量の重要度を横棒グラフで表示する\"\"\"\n",
    "        models_with_importances = [\n",
    "            'DecisionTreeClassifier', \n",
    "            'RandomForestClassifier', \n",
    "            'GradientBoostingClassifier'\n",
    "        ]\n",
    "\n",
    "        # 表示するモデルの数をカウント\n",
    "        available_models = [model for model in models_with_importances if model in self.model_scores]\n",
    "        if not available_models:\n",
    "            print(\"特徴量の重要度を持つモデルが見つかりません。先に all_supervised() を実行してください。\")\n",
    "            return None\n",
    "\n",
    "        # 図を作成\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Irisデータセットの特徴量名をそのまま使用\n",
    "        feature_names = self.feature_names\n",
    "\n",
    "        for i, model_name in enumerate(models_with_importances):\n",
    "            if model_name not in self.model_scores:\n",
    "                continue\n",
    "        \n",
    "            # モデルを再学習\n",
    "            if model_name == 'DecisionTreeClassifier':\n",
    "                model = DecisionTreeClassifier()\n",
    "            elif model_name == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier()\n",
    "            elif model_name == 'GradientBoostingClassifier':\n",
    "                model = GradientBoostingClassifier()\n",
    "    \n",
    "            model.fit(self.X, self.y)\n",
    "    \n",
    "            # 重要度を取得\n",
    "            importance = model.feature_importances_\n",
    "    \n",
    "            # インデックスでソート（降順）\n",
    "            sorted_indices = np.argsort(importance)\n",
    "    \n",
    "            # サブプロット作成\n",
    "            ax = fig.add_subplot(1, len(available_models), i+1)\n",
    "    \n",
    "            # 横棒グラフの作成\n",
    "            y_pos = np.arange(len(feature_names))\n",
    "            ax.barh(y_pos, importance[sorted_indices], align='center')\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels([feature_names[idx] for idx in sorted_indices])\n",
    "            ax.invert_yaxis()  # 上から下へ値が大きい順に表示\n",
    "            ax.set_xlabel('Feature Importance (0-1.0)')\n",
    "            ax.set_xlim(0, 1.0)  # X軸の範囲を0～1に設定\n",
    "            ax.set_title(f'{model_name}')\n",
    "    \n",
    "        # 全モデルをまとめて1つの図として保存\n",
    "        plt.tight_layout()  # レイアウトを調整\n",
    "        plt.savefig(f'{output_dir}/feature_importance_all_models.png')\n",
    "        plt.close()\n",
    "\n",
    "    def visualize_decision_tree(self):\n",
    "        \"\"\"決定木を可視化する\"\"\"\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(self.X, self.y)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plot_tree(tree, filled=True, feature_names=self.feature_names, class_names=self.target_names)\n",
    "        plt.title('Decision Tree Visualization')\n",
    "        plt.tight_layout()\n",
    "        # ファイルに保存\n",
    "        plt.savefig(f'{output_dir}/decision_tree.png')\n",
    "        plt.close()\n",
    "        return tree\n",
    "\n",
    "    def plot_scaled_data(self):\n",
    "        \"\"\"異なるスケーリング手法でデータを変換し、LinearSVCの結果を評価する\"\"\"\n",
    "        scalers = {\n",
    "            'Original': None,\n",
    "            'MinMaxScaler': MinMaxScaler(),\n",
    "            'StandardScaler': StandardScaler(),\n",
    "            'RobusScaler': RobustScaler(),\n",
    "            'Normalizer': Normalizer()\n",
    "        }\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for train_idx, test_idx in kf.split(self.X):\n",
    "            X_train, X_test = self.X.iloc[train_idx], self.X.iloc[test_idx]\n",
    "            y_train, y_test = self.y.iloc[train_idx], self.y.iloc[test_idx]\n",
    "            \n",
    "            print(\"=\" * 73)\n",
    "            \n",
    "            for name, scaler in scalers.items():\n",
    "                if scaler:\n",
    "                    X_train_scaled = scaler.fit_transform(X_train)\n",
    "                    X_test_scaled = scaler.transform(X_test)\n",
    "                else:\n",
    "                    X_train_scaled = X_train\n",
    "                    X_test_scaled = X_test\n",
    "                \n",
    "                model = LinearSVC(max_iter=1000, dual='auto')\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                train_score = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "                test_score = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "                \n",
    "                print(f\"{name:<15}: test score: {test_score:.3f}      train score: {train_score:.3f}     \")\n",
    "        \n",
    "        print(\"=\" * 73)\n",
    "        \n",
    "        # 最初のスケーリングデータを返す (標準スケーリング)\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X)\n",
    "        return pd.DataFrame(X_scaled, columns=self.feature_names)\n",
    "\n",
    "    def plot_pca(self, n_components=2):\n",
    "        \"\"\"PCA分析を行い結果をプロットする\"\"\"\n",
    "        # データのスケーリング\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X)\n",
    "        \n",
    "        # PCA実行\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # 結果をデータフレーム化\n",
    "        df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "        df_pca['species'] = self.data['species']\n",
    "        \n",
    "        # プロット\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='species', palette='viridis', s=100)\n",
    "        plt.title('PCA of Iris Dataset')\n",
    "        \n",
    "        # 主成分の寄与率\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        plt.xlabel(f'PC1 ({explained_variance[0]:.2f})')\n",
    "        plt.ylabel(f'PC2 ({explained_variance[1]:.2f})')\n",
    "        \n",
    "        plt.savefig(f'{output_dir}/pca_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return pd.DataFrame(X_scaled, columns=self.feature_names), df_pca, pca\n",
    "\n",
    "    def plot_nmf(self, n_components=2):\n",
    "        \"\"\"NMF分析を行い結果をプロットする\"\"\"\n",
    "        # データのスケーリング (負の値は使えないのでMinMaxScalerを使用)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X)\n",
    "        \n",
    "        # NMF実行 (反復回数を増やして警告を減らす)\n",
    "        nmf = NMF(n_components=n_components, random_state=42, max_iter=400)\n",
    "        X_nmf = nmf.fit_transform(X_scaled)\n",
    "        \n",
    "        # 結果をデータフレーム化\n",
    "        df_nmf = pd.DataFrame(X_nmf, columns=[f'NMF{i+1}' for i in range(n_components)])\n",
    "        df_nmf['species'] = self.data['species']\n",
    "        \n",
    "        # プロット\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(data=df_nmf, x='NMF1', y='NMF2', hue='species', palette='viridis', s=100)\n",
    "        plt.title('NMF of Iris Dataset')\n",
    "        plt.savefig(f'{output_dir}/nmf_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return pd.DataFrame(X_scaled, columns=self.feature_names), df_nmf, nmf\n",
    "\n",
    "    def plot_tsne(self):\n",
    "        \"\"\"t-SNE分析を行い結果をプロットする\"\"\"\n",
    "        # t-SNE実行 (スケールしていない元データを使用)\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        X_tsne = tsne.fit_transform(self.X)\n",
    "        \n",
    "        # 結果をデータフレーム化\n",
    "        df_tsne = pd.DataFrame(X_tsne, columns=['t-SNE1', 't-SNE2'])\n",
    "        df_tsne['species'] = self.data['species']\n",
    "        \n",
    "        # プロット\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(data=df_tsne, x='t-SNE1', y='t-SNE2', hue='species', palette='viridis', s=100)\n",
    "        plt.title('t-SNE of Iris Dataset')\n",
    "        plt.savefig(f'{output_dir}/tsne_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return df_tsne\n",
    "\n",
    "    def plot_k_means(self):\n",
    "        \"\"\"K-means分析を行い結果をプロットする\"\"\"\n",
    "        # K-means実行\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        clusters = kmeans.fit_predict(self.X)\n",
    "        \n",
    "        # 結果をデータフレーム化\n",
    "        df_kmeans = self.X.copy()\n",
    "        df_kmeans['cluster'] = clusters\n",
    "        df_kmeans['actual'] = self.y\n",
    "        \n",
    "        # プロット\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # K-means結果\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.scatterplot(x=self.X.iloc[:, 0], y=self.X.iloc[:, 1], hue=clusters, palette='viridis', s=100)\n",
    "        plt.title('K-means Clustering')\n",
    "        plt.xlabel(self.feature_names[0])\n",
    "        plt.ylabel(self.feature_names[1])\n",
    "        \n",
    "        # 実際のラベル\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.scatterplot(x=self.X.iloc[:, 0], y=self.X.iloc[:, 1], hue=self.y, palette='viridis', s=100)\n",
    "        plt.title('Actual Classes')\n",
    "        plt.xlabel(self.feature_names[0])\n",
    "        plt.ylabel(self.feature_names[1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/kmeans_analysis.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"KMeans法で予測したラベル:\")\n",
    "        print(clusters)\n",
    "        print(\"\\n実際のラベル:\")\n",
    "        print(self.y.values)\n",
    "        \n",
    "        return df_kmeans\n",
    "\n",
    "    def plot_dendrogram(self, truncate=False):\n",
    "        \"\"\"階層的クラスタリングのデンドログラムをプロットする\"\"\"\n",
    "        try:\n",
    "            # リンケージ行列を計算 (DataFrameをnumpy arrayに変換)\n",
    "            X_array = self.X.values\n",
    "            linked = linkage(X_array, 'ward')\n",
    "            \n",
    "            # デンドログラムをプロット\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            dendrogram(\n",
    "                linked,\n",
    "                truncate_mode='lastp' if truncate else None,\n",
    "                p=10 if truncate else None,\n",
    "                leaf_font_size=10.,\n",
    "                orientation='top'\n",
    "            )\n",
    "            plt.title('Hierarchical Clustering Dendrogram')\n",
    "            plt.xlabel('Sample index')\n",
    "            plt.ylabel('Distance')\n",
    "            \n",
    "            # ファイル名に truncated を追加するかどうか\n",
    "            truncate_str = \"_truncated\" if truncate else \"\"\n",
    "            plt.savefig(f'{output_dir}/dendrogram{truncate_str}.png')\n",
    "            plt.close()\n",
    "            \n",
    "            return linked\n",
    "        except Exception as e:\n",
    "            print(f\"デンドログラムの作成中にエラーが発生しました: {e}\")\n",
    "            return None\n",
    "\n",
    "    def plot_dbscan(self, scaling=False, eps=0.5, min_samples=5):\n",
    "        \"\"\"DBSCAN分析を行い結果をプロットする\"\"\"\n",
    "        # データのスケーリング (オプション)\n",
    "        if scaling:\n",
    "            scaler = StandardScaler()\n",
    "            X_dbscan = scaler.fit_transform(self.X)\n",
    "        else:\n",
    "            X_dbscan = self.X.values\n",
    "        \n",
    "        # DBSCAN実行\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        clusters = dbscan.fit_predict(X_dbscan)\n",
    "        \n",
    "        # 結果をデータフレーム化\n",
    "        df_dbscan = self.X.copy()\n",
    "        df_dbscan['cluster'] = clusters\n",
    "        \n",
    "        try:\n",
    "            # 特徴量の組み合わせをプロット\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "            \n",
    "            # プロットのためのカラーマップ (-1はノイズ点で黒にする)\n",
    "            cmap = plt.cm.viridis\n",
    "            cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "            cmaplist[0] = (0, 0, 0, 1.0)  # ノイズ点を黒に\n",
    "            cmap_custom = plt.matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "            \n",
    "            # 特徴量ペアのプロット\n",
    "            feature_pairs = [\n",
    "                (0, 1), (0, 2), (0, 3),\n",
    "                (1, 2), (1, 3), (2, 3)\n",
    "            ]\n",
    "            \n",
    "            for i, (f1, f2) in enumerate(feature_pairs):\n",
    "                row, col = i // 3, i % 3\n",
    "                axes[row, col].scatter(X_dbscan[:, f1], X_dbscan[:, f2], c=clusters, cmap=cmap_custom, s=50)\n",
    "                axes[row, col].set_xlabel(self.feature_names[f1])\n",
    "                axes[row, col].set_ylabel(self.feature_names[f2])\n",
    "                axes[row, col].set_title(f'{self.feature_names[f1]} vs {self.feature_names[f2]}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.suptitle('DBSCAN Clustering' + (' (Scaled)' if scaling else ''), y=1.02, fontsize=16)\n",
    "            \n",
    "            # スケーリングの有無をファイル名に反映\n",
    "            scaled_str = \"_scaled\" if scaling else \"\"\n",
    "            plt.savefig(f'{output_dir}/dbscan{scaled_str}.png')\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"DBSCAN散布図の作成中にエラーが発生しました: {e}\")\n",
    "        \n",
    "        print(\"Cluster Memberships:\", clusters)\n",
    "        \n",
    "        return df_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015ba81-b348-47df-9ac1-ecb322695f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Irisデータセット分析スクリプト =====\n",
      "Matplotlibのバックエンド: Agg\n",
      "\n",
      "==================================================\n",
      "Irisデータセット分析メニュー\n",
      "==================================================\n",
      "1.  データの読み込み\n",
      "2.  相関分析\n",
      "3.  ペアプロット (ヒストグラム)\n",
      "4.  ペアプロット (KDE)\n",
      "5.  教師あり学習モデルの評価\n",
      "6.  学習結果の取得\n",
      "7.  結果の要約統計量\n",
      "8.  最良のモデルを特定\n",
      "9.  特徴量の重要度を可視化\n",
      "10. 決定木の可視化\n",
      "11. データスケーリング効果を確認\n",
      "12. PCA分析\n",
      "13. NMF分析\n",
      "14. t-SNE分析\n",
      "15. K-means分析\n",
      "16. 階層的クラスタリング\n",
      "17. 簡略化したデンドログラム\n",
      "18. DBSCAN分析\n",
      "19. スケーリングありのDBSCAN分析\n",
      "20. クラスタリング手法の比較\n",
      "0.  終了\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "タスク 1: Irisデータセットの読み込み\n",
      "==================================================\n",
      "データサイズ: (150, 6)\n",
      "データサンプル:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                 5.1               3.5                1.4               0.2   \n",
      "1                 4.9               3.0                1.4               0.2   \n",
      "2                 4.7               3.2                1.3               0.2   \n",
      "3                 4.6               3.1                1.5               0.2   \n",
      "4                 5.0               3.6                1.4               0.2   \n",
      "5                 5.4               3.9                1.7               0.4   \n",
      "6                 4.6               3.4                1.4               0.3   \n",
      "7                 5.0               3.4                1.5               0.2   \n",
      "8                 4.4               2.9                1.4               0.2   \n",
      "9                 4.9               3.1                1.5               0.1   \n",
      "10                5.4               3.7                1.5               0.2   \n",
      "11                4.8               3.4                1.6               0.2   \n",
      "12                4.8               3.0                1.4               0.1   \n",
      "13                4.3               3.0                1.1               0.1   \n",
      "14                5.8               4.0                1.2               0.2   \n",
      "15                5.7               4.4                1.5               0.4   \n",
      "16                5.4               3.9                1.3               0.4   \n",
      "17                5.1               3.5                1.4               0.3   \n",
      "18                5.7               3.8                1.7               0.3   \n",
      "19                5.1               3.8                1.5               0.3   \n",
      "\n",
      "    target species  \n",
      "0        0  setosa  \n",
      "1        0  setosa  \n",
      "2        0  setosa  \n",
      "3        0  setosa  \n",
      "4        0  setosa  \n",
      "5        0  setosa  \n",
      "6        0  setosa  \n",
      "7        0  setosa  \n",
      "8        0  setosa  \n",
      "9        0  setosa  \n",
      "10       0  setosa  \n",
      "11       0  setosa  \n",
      "12       0  setosa  \n",
      "13       0  setosa  \n",
      "14       0  setosa  \n",
      "15       0  setosa  \n",
      "16       0  setosa  \n",
      "17       0  setosa  \n",
      "18       0  setosa  \n",
      "19       0  setosa  \n",
      "\n",
      "==================================================\n",
      "Irisデータセット分析メニュー\n",
      "==================================================\n",
      "1.  データの読み込み\n",
      "2.  相関分析\n",
      "3.  ペアプロット (ヒストグラム)\n",
      "4.  ペアプロット (KDE)\n",
      "5.  教師あり学習モデルの評価\n",
      "6.  学習結果の取得\n",
      "7.  結果の要約統計量\n",
      "8.  最良のモデルを特定\n",
      "9.  特徴量の重要度を可視化\n",
      "10. 決定木の可視化\n",
      "11. データスケーリング効果を確認\n",
      "12. PCA分析\n",
      "13. NMF分析\n",
      "14. t-SNE分析\n",
      "15. K-means分析\n",
      "16. 階層的クラスタリング\n",
      "17. 簡略化したデンドログラム\n",
      "18. DBSCAN分析\n",
      "19. スケーリングありのDBSCAN分析\n",
      "20. クラスタリング手法の比較\n",
      "0.  終了\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "タスク 3: ペアプロット (対角線にヒストグラム)\n",
      "==================================================\n",
      "ペアプロットを保存しました: output/pairplot.png\n",
      "\n",
      "==================================================\n",
      "Irisデータセット分析メニュー\n",
      "==================================================\n",
      "1.  データの読み込み\n",
      "2.  相関分析\n",
      "3.  ペアプロット (ヒストグラム)\n",
      "4.  ペアプロット (KDE)\n",
      "5.  教師あり学習モデルの評価\n",
      "6.  学習結果の取得\n",
      "7.  結果の要約統計量\n",
      "8.  最良のモデルを特定\n",
      "9.  特徴量の重要度を可視化\n",
      "10. 決定木の可視化\n",
      "11. データスケーリング効果を確認\n",
      "12. PCA分析\n",
      "13. NMF分析\n",
      "14. t-SNE分析\n",
      "15. K-means分析\n",
      "16. 階層的クラスタリング\n",
      "17. 簡略化したデンドログラム\n",
      "18. DBSCAN分析\n",
      "19. スケーリングありのDBSCAN分析\n",
      "20. クラスタリング手法の比較\n",
      "0.  終了\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "タスク 9: 特徴量の重要度をプロット\n",
      "==================================================\n",
      "特徴量重要度のプロット中にエラーが発生しました: Figure.savefig() missing 1 required positional argument: 'fname'\n",
      "\n",
      "==================================================\n",
      "Irisデータセット分析メニュー\n",
      "==================================================\n",
      "1.  データの読み込み\n",
      "2.  相関分析\n",
      "3.  ペアプロット (ヒストグラム)\n",
      "4.  ペアプロット (KDE)\n",
      "5.  教師あり学習モデルの評価\n",
      "6.  学習結果の取得\n",
      "7.  結果の要約統計量\n",
      "8.  最良のモデルを特定\n",
      "9.  特徴量の重要度を可視化\n",
      "10. 決定木の可視化\n",
      "11. データスケーリング効果を確認\n",
      "12. PCA分析\n",
      "13. NMF分析\n",
      "14. t-SNE分析\n",
      "15. K-means分析\n",
      "16. 階層的クラスタリング\n",
      "17. 簡略化したデンドログラム\n",
      "18. DBSCAN分析\n",
      "19. スケーリングありのDBSCAN分析\n",
      "20. クラスタリング手法の比較\n",
      "0.  終了\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import matplotlib\n",
    "import sys\n",
    "from iris import AnalyzeIris\n",
    "\n",
    "def print_task_header(task_number, task_name):\n",
    "    \"\"\"タスクのヘッダーを表示する\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"タスク {task_number}: {task_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def task_1_load_data():\n",
    "    \"\"\"課題1: データの読み込み\"\"\"\n",
    "    print_task_header(1, \"Irisデータセットの読み込み\")\n",
    "    \n",
    "    iris = AnalyzeIris()\n",
    "    data = iris.get()\n",
    "    print(f\"データサイズ: {data.shape}\")\n",
    "    print(\"データサンプル:\")\n",
    "    print(data.head(20))\n",
    "    \n",
    "    return iris\n",
    "\n",
    "def task_2_correlation(iris):\n",
    "    \"\"\"課題2: 相関分析\"\"\"\n",
    "    print_task_header(2, \"変数間の相関関係を確認\")\n",
    "    \n",
    "    try:\n",
    "        correlation = iris.get_correlation()\n",
    "        print(\"相関行列:\")\n",
    "        print(correlation)\n",
    "    except Exception as e:\n",
    "        print(f\"相関行列の表示中にエラーが発生しました: {e}\")\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "def task_3_pair_plot(iris):\n",
    "    \"\"\"課題3: ペアプロット (ヒストグラム)\"\"\"\n",
    "    print_task_header(3, \"ペアプロット (対角線にヒストグラム)\")\n",
    "    \n",
    "    try:\n",
    "        df = iris.pair_plot()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"ペアプロットの表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_4_pair_plot_kde(iris):\n",
    "    \"\"\"課題4: ペアプロット (KDE)\"\"\"\n",
    "    print_task_header(4, \"ペアプロット (対角線にカーネル密度推定)\")\n",
    "    \n",
    "    try:\n",
    "        df = iris.pair_plot(diag_kind=\"kde\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"KDEペアプロットの表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_5_supervised_learning(iris):\n",
    "    \"\"\"課題5: 教師あり学習モデルの評価\"\"\"\n",
    "    print_task_header(5, \"複数の教師あり学習モデルを評価\")\n",
    "    \n",
    "    print(\"9つのモデルをクロスバリデーションで評価します...\")\n",
    "    model_scores = iris.all_supervised(n_neighbors=4)\n",
    "    return model_scores\n",
    "\n",
    "def task_6_get_learning_results(iris):\n",
    "    \"\"\"課題6: 学習結果の取得\"\"\"\n",
    "    print_task_header(6, \"学習結果をデータフレームで取得\")\n",
    "    \n",
    "    df_scores = iris.get_supervised()\n",
    "    print(df_scores.head(15))  # 最初の数行を表示\n",
    "    return df_scores\n",
    "\n",
    "def task_7_summary_stats(df_scores):\n",
    "    \"\"\"課題7: 結果の要約統計量\"\"\"\n",
    "    print_task_header(7, \"スコアの要約統計量\")\n",
    "    \n",
    "    if df_scores is not None:\n",
    "        df_summary = df_scores.describe()\n",
    "        print(df_summary)\n",
    "        return df_summary\n",
    "    else:\n",
    "        print(\"スコアデータが見つかりません。先に課題5と6を実行してください。\")\n",
    "        return None\n",
    "\n",
    "def task_8_best_model(iris):\n",
    "    \"\"\"課題8: 最良のモデルを特定\"\"\"\n",
    "    print_task_header(8, \"最良のモデルを特定\")\n",
    "    \n",
    "    best_method, best_score = iris.best_supervised()\n",
    "    print(f\"BestMethod is {best_method} : {best_score:.4f}\")\n",
    "    return best_method, best_score\n",
    "\n",
    "def task_9_feature_importance(iris):\n",
    "    \"\"\"課題9: 特徴量の重要度を可視化\"\"\"\n",
    "    print_task_header(9, \"特徴量の重要度をプロット\")\n",
    "    \n",
    "    try:\n",
    "        iris.plot_feature_importances_all()\n",
    "    except Exception as e:\n",
    "        print(f\"特徴量重要度の表示中にエラーが発生しました: {e}\")\n",
    "\n",
    "def task_10_decision_tree(iris):\n",
    "    \"\"\"課題10: 決定木の可視化\"\"\"\n",
    "    print_task_header(10, \"決定木を可視化\")\n",
    "    \n",
    "    try:\n",
    "        tree = iris.visualize_decision_tree()\n",
    "        return tree\n",
    "    except Exception as e:\n",
    "        print(f\"決定木の表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_11_data_scaling(iris):\n",
    "    \"\"\"課題11: データスケーリングとその効果\"\"\"\n",
    "    print_task_header(11, \"異なるスケーリング手法の効果を確認\")\n",
    "    \n",
    "    print(\"各スケーリング手法でLinearSVCを評価します...\")\n",
    "    train_data = iris.plot_scaled_data()\n",
    "    return train_data\n",
    "\n",
    "def task_12_pca(iris):\n",
    "    \"\"\"課題12: PCA分析\"\"\"\n",
    "    print_task_header(12, \"PCA (主成分分析)\")\n",
    "    \n",
    "    try:\n",
    "        X_scaled, df_pca, pca = iris.plot_pca(n_components=2)\n",
    "        print(\"PCAの主成分:\")\n",
    "        print(pca.components_)\n",
    "        return X_scaled, df_pca, pca\n",
    "    except Exception as e:\n",
    "        print(f\"PCA分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def task_13_nmf(iris):\n",
    "    \"\"\"課題13: NMF分析\"\"\"\n",
    "    print_task_header(13, \"NMF (非負値行列因子分解)\")\n",
    "    \n",
    "    try:\n",
    "        X_scaled, df_nmf, nmf = iris.plot_nmf(n_components=2)\n",
    "        return X_scaled, df_nmf, nmf\n",
    "    except Exception as e:\n",
    "        print(f\"NMF分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def task_14_tsne(iris):\n",
    "    \"\"\"課題14: t-SNE分析\"\"\"\n",
    "    print_task_header(14, \"t-SNE分析\")\n",
    "    \n",
    "    try:\n",
    "        df_tsne = iris.plot_tsne()\n",
    "        return df_tsne\n",
    "    except Exception as e:\n",
    "        print(f\"t-SNE分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_15_kmeans(iris):\n",
    "    \"\"\"課題15: K-means分析\"\"\"\n",
    "    print_task_header(15, \"K-means分析\")\n",
    "    \n",
    "    try:\n",
    "        df_kmeans = iris.plot_k_means()\n",
    "        return df_kmeans\n",
    "    except Exception as e:\n",
    "        print(f\"K-means分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_16_dendrogram(iris):\n",
    "    \"\"\"課題16: 階層的クラスタリング (デンドログラム)\"\"\"\n",
    "    print_task_header(16, \"階層的クラスタリング (デンドログラム)\")\n",
    "    \n",
    "    try:\n",
    "        linked = iris.plot_dendrogram()\n",
    "        return linked\n",
    "    except Exception as e:\n",
    "        print(f\"デンドログラムの表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_17_truncated_dendrogram(iris):\n",
    "    \"\"\"課題17: 簡略化したデンドログラム\"\"\"\n",
    "    print_task_header(17, \"簡略化したデンドログラム\")\n",
    "    \n",
    "    try:\n",
    "        linked = iris.plot_dendrogram(truncate=True)\n",
    "        return linked\n",
    "    except Exception as e:\n",
    "        print(f\"簡略化デンドログラムの表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_18_dbscan(iris):\n",
    "    \"\"\"課題18: DBSCAN分析\"\"\"\n",
    "    print_task_header(18, \"DBSCAN分析\")\n",
    "    \n",
    "    try:\n",
    "        df_dbscan = iris.plot_dbscan()\n",
    "        return df_dbscan\n",
    "    except Exception as e:\n",
    "        print(f\"DBSCAN分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_19_scaled_dbscan(iris):\n",
    "    \"\"\"課題19: スケーリングありのDBSCAN分析\"\"\"\n",
    "    print_task_header(19, \"スケーリングありのDBSCAN分析\")\n",
    "    \n",
    "    try:\n",
    "        df_dbscan_scaled = iris.plot_dbscan(scaling=True, eps=0.5, min_samples=5)\n",
    "        return df_dbscan_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"スケーリングありDBSCAN分析の表示中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def task_20_clustering_comparison():\n",
    "    \"\"\"課題20: クラスタリング手法の比較\"\"\"\n",
    "    print_task_header(20, \"最終課題: クラスタリング手法の比較\")\n",
    "    \n",
    "    comparison = \"\"\"\n",
    "    KMeans, 階層的クラスタリング, DBSCANの比較:\n",
    "    \n",
    "    1. K-means:\n",
    "       - 長所: 単純で理解しやすい、計算効率が良い\n",
    "       - 短所: クラスタ数を事前指定、球形クラスタのみ対応\n",
    "       - Irisデータでは: k=3で比較的適切に機能するが、完全には分離できない\n",
    "       \n",
    "    2. 階層的クラスタリング:\n",
    "       - 長所: クラスタ数事前指定不要、階層関係を視覚化\n",
    "       - 短所: 計算コスト高、大規模データに不向き\n",
    "       - Irisデータでは: 種の分類学的関係を明確に示す\n",
    "       \n",
    "    3. DBSCAN:\n",
    "       - 長所: クラスタ数事前指定不要、異常値検出、任意形状対応\n",
    "       - 短所: パラメータ設定が難しい、密度差のあるクラスタに弱い\n",
    "       - Irisデータでは: パラメータによって結果が大きく変わる\n",
    "       \n",
    "    結論: Irisデータセットでは種の数が既知なのでK-meansが単純かつ効果的ですが、\n",
    "    実際の応用では事前知識の有無によって最適手法が異なります。\n",
    "    \"\"\"\n",
    "    \n",
    "    print(comparison)\n",
    "    return comparison\n",
    "\n",
    "def print_menu():\n",
    "    \"\"\"メニューを表示する\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Irisデータセット分析メニュー\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1.  データの読み込み\")\n",
    "    print(\"2.  相関分析\")\n",
    "    print(\"3.  ペアプロット (ヒストグラム)\")\n",
    "    print(\"4.  ペアプロット (KDE)\")\n",
    "    print(\"5.  教師あり学習モデルの評価\")\n",
    "    print(\"6.  学習結果の取得\")\n",
    "    print(\"7.  結果の要約統計量\")\n",
    "    print(\"8.  最良のモデルを特定\")\n",
    "    print(\"9.  特徴量の重要度を可視化\")\n",
    "    print(\"10. 決定木の可視化\")\n",
    "    print(\"11. データスケーリング効果を確認\")\n",
    "    print(\"12. PCA分析\")\n",
    "    print(\"13. NMF分析\")\n",
    "    print(\"14. t-SNE分析\")\n",
    "    print(\"15. K-means分析\")\n",
    "    print(\"16. 階層的クラスタリング\")\n",
    "    print(\"17. 簡略化したデンドログラム\")\n",
    "    print(\"18. DBSCAN分析\")\n",
    "    print(\"19. スケーリングありのDBSCAN分析\")\n",
    "    print(\"20. クラスタリング手法の比較\")\n",
    "    print(\"0.  終了\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def main():\n",
    "    \"\"\"メインプログラム\"\"\"\n",
    "    print(\"===== Irisデータセット分析スクリプト =====\")\n",
    "    print(f\"Matplotlibのバックエンド: {matplotlib.get_backend()}\")\n",
    "    \n",
    "    iris = None\n",
    "    df_scores = None\n",
    "    \n",
    "    while True:\n",
    "        print_menu()\n",
    "        try:\n",
    "            choice = int(input(\"実行する課題番号を入力してください (0-20): \"))\n",
    "        except ValueError:\n",
    "            print(\"数字を入力してください\")\n",
    "            continue\n",
    "        \n",
    "        if choice == 0:\n",
    "            print(\"プログラムを終了します\")\n",
    "            break\n",
    "        \n",
    "        if choice == 1:\n",
    "            iris = task_1_load_data()\n",
    "        elif choice >= 2 and choice <= 20:\n",
    "            if iris is None and choice <= 19:\n",
    "                print(\"先に課題1を実行してデータをロードしてください\")\n",
    "                continue\n",
    "                \n",
    "            if choice == 2:\n",
    "                task_2_correlation(iris)\n",
    "            elif choice == 3:\n",
    "                task_3_pair_plot(iris)\n",
    "            elif choice == 4:\n",
    "                task_4_pair_plot_kde(iris)\n",
    "            elif choice == 5:\n",
    "                task_5_supervised_learning(iris)\n",
    "            elif choice == 6:\n",
    "                df_scores = task_6_get_learning_results(iris)\n",
    "            elif choice == 7:\n",
    "                task_7_summary_stats(df_scores)\n",
    "            elif choice == 8:\n",
    "                task_8_best_model(iris)\n",
    "            elif choice == 9:\n",
    "                task_9_feature_importance(iris)\n",
    "            elif choice == 10:\n",
    "                task_10_decision_tree(iris)\n",
    "            elif choice == 11:\n",
    "                task_11_data_scaling(iris)\n",
    "            elif choice == 12:\n",
    "                task_12_pca(iris)\n",
    "            elif choice == 13:\n",
    "                task_13_nmf(iris)\n",
    "            elif choice == 14:\n",
    "                task_14_tsne(iris)\n",
    "            elif choice == 15:\n",
    "                task_15_kmeans(iris)\n",
    "            elif choice == 16:\n",
    "                task_16_dendrogram(iris)\n",
    "            elif choice == 17:\n",
    "                task_17_truncated_dendrogram(iris)\n",
    "            elif choice == 18:\n",
    "                task_18_dbscan(iris)\n",
    "            elif choice == 19:\n",
    "                task_19_scaled_dbscan(iris)\n",
    "            elif choice == 20:\n",
    "                task_20_clustering_comparison()\n",
    "        else:\n",
    "            print(\"1から20までの数字を入力してください\")\n",
    "    \n",
    "    print(\"\\n===== 分析終了 =====\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d9004-1276-4e83-99ad-17574f36a14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
