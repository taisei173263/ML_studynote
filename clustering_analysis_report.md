# Irisデータセットを用いたクラスタリングアルゴリズムの比較分析

## 1. はじめに

クラスタリングは教師なし学習の手法の一つで、データポイントの類似性に基づいてグループ（クラスタ）に分類する方法です。本レポートでは、機械学習の分野で有名なIrisデータセットを用いて、3つの代表的なクラスタリングアルゴリズム（K-means、階層的クラスタリング、DBSCAN）を実装・比較し、それぞれの特徴と適切な使用場面について考察します。

## 2. 使用データセット

Irisデータセットは以下の特徴を持ちます：

- 3種類のアヤメ（Setosa、Versicolor、Virginica）それぞれ50サンプル、計150サンプル
- 各サンプルは4つの特徴量を持つ：
  - 萼片（がくへん）の長さ (Sepal Length)
  - 萼片の幅 (Sepal Width)
  - 花弁の長さ (Petal Length)
  - 花弁の幅 (Petal Width)

今回の分析ではサンプルとして各種類20サンプルずつ、計60サンプルを使用しました。

## 3. クラスタリングアルゴリズムの概要

### 3.1 K-means

K-meansは、データポイントをk個のクラスタに分類するアルゴリズムです。あらかじめクラスタ数kを指定する必要があります。

**アルゴリズムの流れ**：
1. k個の初期クラスタ中心をランダムに選択
2. 各データポイントを最も近いクラスタ中心に割り当て
3. 各クラスタに割り当てられたデータポイントの平均位置を新しいクラスタ中心とする
4. クラスタの割り当てに変化がなくなるまで2~3を繰り返す

**特徴**：
- 実装が簡単で計算効率が良い
- 球形のクラスタを仮定する
- 初期値に依存する

### 3.2 階層的クラスタリング（Dendrogram）

階層的クラスタリングは、データポイント間の距離に基づいて階層的なクラスタ構造を構築します。

**アルゴリズムの流れ（凝集型）**：
1. 各データポイントを独立したクラスタとする
2. 最も近い2つのクラスタを見つけて統合
3. 目標クラスタ数になるまで2を繰り返す

**特徴**：
- クラスタ間の距離の定義によって異なる結果が得られる（単連結法、完全連結法、Ward法など）
- 階層的な構造をデンドログラム（樹形図）で可視化できる
- 計算量がO(n^3)と比較的大きい

### 3.3 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

DBSCANは密度ベースのクラスタリングアルゴリズムで、データの密度に基づいてクラスタを形成します。

**アルゴリズムの流れ**：
1. パラメータε（近傍の半径）とMinPts（最小点数）を設定
2. 各点のε-近傍に含まれる点の数を数える
3. MinPts以上の点を含む点をコア点とし、コア点から連続的に到達可能な点の集合をクラスタとする
4. どのクラスタにも属さない点をノイズ（外れ値）とする

**特徴**：
- クラスタ数を事前に指定する必要がない
- 任意の形状のクラスタを検出できる
- ノイズ点を識別できる
- パラメータ設定が難しい場合がある

## 4. 実装と結果

各アルゴリズムをJavaScriptで実装し、Irisデータセットに適用した結果を以下に示します。

### 4.1 前処理とデータ可視化

4次元のIrisデータは主成分分析（PCA）を用いて2次元に次元削減し可視化しました。

### 4.2 クラスタリング結果

各アルゴリズムの精度（実際のIrisの種類とクラスタの一致度）：

- **K-means (k=3)**: 精度 88.33%
  - クラスタ構成: クラスタ0: 17サンプル, クラスタ1: 20サンプル, クラスタ2: 23サンプル
  - 3回の反復で収束

- **階層的クラスタリング (k=3)**: 精度 70.00%
  - クラスタ構成: クラスタ0: 20サンプル, クラスタ1: 38サンプル, クラスタ2: 2サンプル
  - 極端に不均衡なクラスタサイズ

- **DBSCAN (eps=0.8, minPts=4)**: ノイズを除く精度 69.09%
  - クラスタ構成: ノイズ: 5サンプル, クラスタ1: 20サンプル, クラスタ2: 35サンプル
  - 2つの主要クラスタとノイズポイントを検出

## 5. アルゴリズムの比較考察

### 5.1 精度の比較

今回の実験では、K-meansが最も高い精度（88.33%）を示しました。これはIrisデータセットの特性（比較的球形に近いクラスタ構造）とK-meansの特性がマッチしたためと考えられます。階層的クラスタリングとDBSCANは70%前後の精度でした。

### 5.2 クラスタ形状と均衡性

- **K-means**: 比較的均衡の取れたクラスタサイズで、実際のIris種との対応も良好
- **階層的クラスタリング**: 極端に偏ったクラスタサイズで、特に小さなクラスタ（2サンプル）の存在が特徴的
- **DBSCAN**: 2つの主要クラスタとノイズポイントを検出し、実際のデータの密度構造を反映

### 5.3 計算効率

K-meansは3回の反復で収束し、計算効率が良いことが確認できました。階層的クラスタリングとDBSCANはより計算コストが高いですが、それぞれ異なる視点でデータ構造を捉えることができました。

## 6. 各アルゴリズムの適切な使用場面

### 6.1 K-meansが適している場合

- クラスタ数が事前にわかっている場合
- クラスタが球形に近い形状と予想される場合
- 大規模データセットで計算効率が重要な場合
- データの密度が均一な場合

**実例**: 顧客セグメンテーション、画像の色量子化、文書のトピック分類など

### 6.2 階層的クラスタリングが適している場合

- クラスタの階層構造を把握したい場合
- クラスタ数が事前にわからない場合
- データサイズが比較的小さい場合（計算量の問題）
- 様々な粒度でのクラスタリング結果を比較したい場合

**実例**: 遺伝子発現データ分析、系統樹作成、市場セグメンテーションの階層的把握など

### 6.3 DBSCANが適している場合

- クラスタの形状が不規則な場合
- ノイズ（外れ値）の検出が重要な場合
- クラスタ密度が不均一な場合
- クラスタ数が事前にわからない場合

**実例**: 地理空間データの分析、異常検知、複雑なパターン認識など

## 7. 結論

Irisデータセットのクラスタリング分析を通じて、各アルゴリズムの特性と使い分けについて考察しました。

- **K-means**は球形クラスタを仮定し、計算効率が良く、Irisデータに対して高い精度を示しました
- **階層的クラスタリング**はクラスタの階層構造を示す利点がありますが、不均衡なクラスタを形成する傾向がありました
- **DBSCAN**は密度ベースのアプローチにより、ノイズ点を識別し実データの密度構造を反映しました

クラスタリングアルゴリズムの選択は、データの特性、分析の目的、計算リソースなどに応じて適切に行うことが重要です。今回の分析では、Irisデータセットに対してはK-meansが最も適していましたが、データの性質が異なれば他のアルゴリズムが優位性を示す可能性があります。

実務においては、複数のクラスタリングアルゴリズムを試し、結果を比較検討することが推奨されます。また、アルゴリズムのパラメータチューニングや適切な評価指標の選択も重要な検討事項です。

---

## 参考文献

1. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
2. Han, J., Kamber, M., & Pei, J. (2012). Data Mining: Concepts and Techniques. Morgan Kaufmann.
3. Ester, M., Kriegel, H.-P., Sander, J., & Xu, X. (1996). A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. KDD-96.
